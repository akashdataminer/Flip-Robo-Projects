{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "\n",
    "# Importing the required libraries into Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Q1: Write a python program to scrape data for “Data Analyst” Job position in \n",
    "“Bangalore” location. You have to scrape the job-title, job-location, company_name,\n",
    "experience_required. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Analyst” in “Skill,Designations,Companies” field and enter “Bangalore” \n",
    "in “enter the location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experience_required</th>\n",
       "      <th>company_name</th>\n",
       "      <th>job_location</th>\n",
       "      <th>job_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3-5 Yrs</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Data analysts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5-6 Yrs</td>\n",
       "      <td>(9912 Reviews)</td>\n",
       "      <td>Bengaluru/Bangalore</td>\n",
       "      <td>Data analysts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0-4 Yrs</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2-3 Yrs</td>\n",
       "      <td>(9912 Reviews)</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Consultant-Data Analyst -Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>Zilingo.com</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Data Analyst / Sr. Data Analyst - SQL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4-6 Yrs</td>\n",
       "      <td>(11 Reviews)</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Senior Associate - Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3-6 Yrs</td>\n",
       "      <td>Innovsource Services Private Limited</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Data Analyst (Ops portal)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3-5 Yrs</td>\n",
       "      <td>(641 Reviews)</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>Naukri Premium - Employer Services</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4-8 Yrs</td>\n",
       "      <td>Sapient</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Advanced Services Engineer - Data Analyst</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  experience_required                          company_name  \\\n",
       "0             3-5 Yrs                IBM India Pvt. Limited   \n",
       "1             5-6 Yrs                        (9912 Reviews)   \n",
       "2             0-4 Yrs                IBM India Pvt. Limited   \n",
       "3             2-3 Yrs                        (9912 Reviews)   \n",
       "4             2-5 Yrs                           Zilingo.com   \n",
       "5             4-6 Yrs                          (11 Reviews)   \n",
       "6             3-6 Yrs  Innovsource Services Private Limited   \n",
       "7             3-5 Yrs                         (641 Reviews)   \n",
       "8             2-5 Yrs    Naukri Premium - Employer Services   \n",
       "9             4-8 Yrs                               Sapient   \n",
       "\n",
       "          job_location                                  job_title  \n",
       "0  Bangalore/Bengaluru                              Data analysts  \n",
       "1  Bengaluru/Bangalore                              Data analysts  \n",
       "2  Bangalore/Bengaluru                               Data Analyst  \n",
       "3  Bangalore/Bengaluru         Consultant-Data Analyst -Bangalore  \n",
       "4  Bangalore/Bengaluru      Data Analyst / Sr. Data Analyst - SQL  \n",
       "5  Bangalore/Bengaluru            Senior Associate - Data Analyst  \n",
       "6  Bangalore/Bengaluru                  Data Analyst (Ops portal)  \n",
       "7  Bangalore/Bengaluru                               Data Analyst  \n",
       "8  Bangalore/Bengaluru                               Data Analyst  \n",
       "9  Bangalore/Bengaluru  Advanced Services Engineer - Data Analyst  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver=webdriver.Edge(r\"C:\\Users\\Akash\\Downloads\\msedgedriver.exe\")\n",
    "time.sleep(4)\n",
    "\n",
    "url = \"https://www.naukri.com/\"\n",
    "driver.get(url)\n",
    "time.sleep(6)\n",
    "\n",
    "# entering Data into Search Bars :-\n",
    "\n",
    "search_field_designation=driver.find_element_by_id(\"qsb-keyword-sugg\") \n",
    "search_field_location=driver.find_element_by_id('qsb-location-sugg') \n",
    "search_field_designation.send_keys(\"Data Analyst\")\n",
    "search_field_location.send_keys(\"Bangalore\")\n",
    "\n",
    "\n",
    "# clicking the search button:-\n",
    "\n",
    "search_button=driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
    "search_button.click()\n",
    "\n",
    "\n",
    "time.sleep(4)\n",
    "\n",
    "# creating empty lists for scraping data and use the scraped data to make DataFrame:-\n",
    "\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]\n",
    "\n",
    "\n",
    "#scraping the job-titles:-\n",
    "\n",
    "titles=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "for i in titles:\n",
    "    if i.text is None :\n",
    "        job_title.append(\"--\") \n",
    "    else:\n",
    "        job_title.append(i.text)\n",
    "\n",
    "time.sleep(4)\n",
    "\n",
    "#scraping the job-location:-\n",
    "\n",
    "locations=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span[1]\")\n",
    "for i in locations:\n",
    "    if i.text is None :\n",
    "        job_location.append(\"--\") \n",
    "    else:\n",
    "        job_location.append(i.text)\n",
    "        \n",
    "time.sleep(4)\n",
    "\n",
    "#scraping the company_name:-\n",
    "\n",
    "companies=driver.find_elements_by_xpath(\"//div[@class='mt-7 companyInfo subheading lh16']/a\")\n",
    "for i in companies:\n",
    "    if i.text is None :\n",
    "        company_name.append(\"--\") \n",
    "    else:\n",
    "        company_name.append(i.text)\n",
    "company_name[0:2]\n",
    "\n",
    "\n",
    "time.sleep(4)\n",
    "\n",
    "#scraping the experience_required:-\n",
    "\n",
    "experience=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span[1]\")\n",
    "for i in experience:\n",
    "    if i.text is None :\n",
    "            experience_required.append(\"--\") \n",
    "    else:\n",
    "            experience_required.append(i.text)\n",
    "\n",
    "\n",
    "time.sleep(4)\n",
    "\n",
    "# creating the dataframe from the scraped data and taking only first 10 jobs:-\n",
    "\n",
    "JOBS=pd.DataFrame({\"experience_required\":experience_required[0:10],\"company_name\":company_name[0:10],\"job_location\":job_location[0:10],\n",
    "                \"job_title\":job_title[0:10]})\n",
    "JOBS\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Q2: Write a python program to scrape data for “Data Scientist” Job position in\n",
    "“Bangalore” location. You have to scrape the job-title, job-location,\n",
    "company_name, full job-description. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill,Designations,Companies” field and enter\n",
    "“Bangalore” in “enter the location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>company_name</th>\n",
       "      <th>job_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist / Data Analyst -Business Analyst</td>\n",
       "      <td>Inflexion Analytix Private Limited</td>\n",
       "      <td>Hyderabad/Secunderabad, Chennai, Bangalore/Ben...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Oracle India Pvt. Ltd.</td>\n",
       "      <td>Noida, Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>(1910 Reviews)</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Baker Hughes - The Network</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>(238 Reviews)</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>FabHotel Aay Kay Model Town</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>(182 Reviews)</td>\n",
       "      <td>Mumbai, Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Becton Dickinson India Pvt Ltd</td>\n",
       "      <td>Chennai, Bangalore/Bengaluru, Vadodara</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lead Data Scientist - Machine Learning/ Data M...</td>\n",
       "      <td>(115 Reviews)</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist IV</td>\n",
       "      <td>24/7 Customer</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           job_title  \\\n",
       "0    Data Scientist / Data Analyst -Business Analyst   \n",
       "1                                     Data Scientist   \n",
       "2                              Senior Data Scientist   \n",
       "3                              Senior Data Scientist   \n",
       "4                                Lead Data Scientist   \n",
       "5                              Senior Data Scientist   \n",
       "6                              Senior Data Scientist   \n",
       "7                              Senior Data Scientist   \n",
       "8  Lead Data Scientist - Machine Learning/ Data M...   \n",
       "9                                  Data Scientist IV   \n",
       "\n",
       "                         company_name  \\\n",
       "0  Inflexion Analytix Private Limited   \n",
       "1              Oracle India Pvt. Ltd.   \n",
       "2                      (1910 Reviews)   \n",
       "3          Baker Hughes - The Network   \n",
       "4                       (238 Reviews)   \n",
       "5         FabHotel Aay Kay Model Town   \n",
       "6                       (182 Reviews)   \n",
       "7      Becton Dickinson India Pvt Ltd   \n",
       "8                       (115 Reviews)   \n",
       "9                       24/7 Customer   \n",
       "\n",
       "                                        job_location  \n",
       "0  Hyderabad/Secunderabad, Chennai, Bangalore/Ben...  \n",
       "1                         Noida, Bangalore/Bengaluru  \n",
       "2                                Bangalore/Bengaluru  \n",
       "3                                Bangalore/Bengaluru  \n",
       "4                                Bangalore/Bengaluru  \n",
       "5                                Bangalore/Bengaluru  \n",
       "6      Mumbai, Gurgaon/Gurugram, Bangalore/Bengaluru  \n",
       "7             Chennai, Bangalore/Bengaluru, Vadodara  \n",
       "8                                Bangalore/Bengaluru  \n",
       "9                                Bangalore/Bengaluru  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver=webdriver.Edge(r\"C:\\Users\\Akash\\Downloads\\msedgedriver.exe\")\n",
    "time.sleep(4)\n",
    "\n",
    "url = \"https://www.naukri.com/\"\n",
    "driver.get(url)\n",
    "time.sleep(6)\n",
    "\n",
    "# entering Data into Search Bars:-\n",
    "\n",
    "search_field_designation=driver.find_element_by_id(\"qsb-keyword-sugg\")   \n",
    "search_field_location=driver.find_element_by_id('qsb-location-sugg') \n",
    "search_field_designation.send_keys(\"Data Scientist\")\n",
    "search_field_location.send_keys(\"Bangalore\")\n",
    "\n",
    "\n",
    "# clicking the search button:-\n",
    "\n",
    "search_button=driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
    "search_button.click()\n",
    "\n",
    "\n",
    "time.sleep(4)\n",
    "\n",
    "# creating empty lists for scraping data:-\n",
    "\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "full_job_description=[]\n",
    "\n",
    "\n",
    "#scraping the job-titles:-\n",
    "\n",
    "titles=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "for i in titles:\n",
    "    if i.text is None :\n",
    "        job_title.append(\"--\") \n",
    "    else:\n",
    "        job_title.append(i.text)\n",
    "\n",
    "time.sleep(4)\n",
    "\n",
    "#scraping the job-location:-\n",
    "\n",
    "locations=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span[1]\")\n",
    "for i in locations:\n",
    "    if i.text is None :\n",
    "        job_location.append(\"--\") \n",
    "    else:\n",
    "        job_location.append(i.text)\n",
    "        \n",
    "time.sleep(4) \n",
    "\n",
    "#scraping the company_name:-\n",
    "\n",
    "companies=driver.find_elements_by_xpath(\"//div[@class='mt-7 companyInfo subheading lh16']/a\")\n",
    "for i in companies:\n",
    "    if i.text is None :\n",
    "        company_name.append(\"--\") \n",
    "    else:\n",
    "        company_name.append(i.text)\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    " # creating the dataframe from the scraped data and taking only first 10 jobs\n",
    "DSJOBS=pd.DataFrame({\"job_title\":job_title[0:10],\"company_name\":company_name[0:10],\"job_location\":job_location[0:10]})\n",
    "DSJOBS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Q3: In this question you have to scrape data using the filters available on the\n",
    "webpage as shown below:\n",
    "You have to use the location and salary filter.\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company_name,\n",
    "experience_required.\n",
    "The location filter to be used is “Delhi/NCR”\n",
    "The salary filter to be used is “3-6” lakhs\n",
    "The task will be done as shown in the below steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill,Designations,Companies” field .\n",
    "3. Then click the search button.\n",
    "4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>experience_required</th>\n",
       "      <th>company_name</th>\n",
       "      <th>job_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist/Data Analyst /Business Analyst</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "      <td>Inflexion Analytix Private Limited</td>\n",
       "      <td>Pune, Delhi / NCR, Mumbai (All Areas)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Advanced Analytics -Data Scientist</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "      <td>ERM Placement Services (P) Ltd.</td>\n",
       "      <td>New Delhi, Hyderabad/Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist - Machine Learning/ NLP</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "      <td>TalPro</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Only Fresher / Data Scientist / Data Analyst /...</td>\n",
       "      <td>0-0 Yrs</td>\n",
       "      <td>GABA Consultancy services</td>\n",
       "      <td>Noida, Gurgaon/Gurugram, Delhi / NCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist - Text NLP | Noida</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "      <td>Acidaes Solutions Pvt. Ltd.</td>\n",
       "      <td>Noida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist - Machine Learning/NLP</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "      <td>(67 Reviews)</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data analytics / Data scientist intern (work f...</td>\n",
       "      <td>0-5 Yrs</td>\n",
       "      <td>TalPro</td>\n",
       "      <td>Kolkata, Bangalore/Bengaluru, Delhi / NCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Chaayos is Looking For Data Scientist</td>\n",
       "      <td>0-5 Yrs</td>\n",
       "      <td>TalkValley LLC</td>\n",
       "      <td>New Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist -Delhi</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "      <td>Chaayos (Sunshine Teahouse Pvt. Ltd.)</td>\n",
       "      <td>New Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "      <td>(159 Reviews)</td>\n",
       "      <td>Mumbai, Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           job_title experience_required  \\\n",
       "0      Data Scientist/Data Analyst /Business Analyst             0-3 Yrs   \n",
       "1                 Advanced Analytics -Data Scientist             3-7 Yrs   \n",
       "2             Data Scientist - Machine Learning/ NLP             2-6 Yrs   \n",
       "3  Only Fresher / Data Scientist / Data Analyst /...             0-0 Yrs   \n",
       "4                  Data Scientist - Text NLP | Noida             3-5 Yrs   \n",
       "5              Data Scientist - Machine Learning/NLP             2-6 Yrs   \n",
       "6  Data analytics / Data scientist intern (work f...             0-5 Yrs   \n",
       "7              Chaayos is Looking For Data Scientist             0-5 Yrs   \n",
       "8                              Data Scientist -Delhi             5-8 Yrs   \n",
       "9                                     Data Scientist             3-7 Yrs   \n",
       "\n",
       "                            company_name  \\\n",
       "0     Inflexion Analytix Private Limited   \n",
       "1        ERM Placement Services (P) Ltd.   \n",
       "2                                 TalPro   \n",
       "3              GABA Consultancy services   \n",
       "4            Acidaes Solutions Pvt. Ltd.   \n",
       "5                           (67 Reviews)   \n",
       "6                                 TalPro   \n",
       "7                         TalkValley LLC   \n",
       "8  Chaayos (Sunshine Teahouse Pvt. Ltd.)   \n",
       "9                          (159 Reviews)   \n",
       "\n",
       "                                    job_location  \n",
       "0          Pune, Delhi / NCR, Mumbai (All Areas)  \n",
       "1              New Delhi, Hyderabad/Secunderabad  \n",
       "2                               Gurgaon/Gurugram  \n",
       "3           Noida, Gurgaon/Gurugram, Delhi / NCR  \n",
       "4                                          Noida  \n",
       "5                               Gurgaon/Gurugram  \n",
       "6      Kolkata, Bangalore/Bengaluru, Delhi / NCR  \n",
       "7                                      New Delhi  \n",
       "8                                      New Delhi  \n",
       "9  Mumbai, Gurgaon/Gurugram, Bangalore/Bengaluru  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver=webdriver.Edge(r\"C:\\Users\\Akash\\Downloads\\msedgedriver.exe\")\n",
    "time.sleep(4)\n",
    "\n",
    "url = \"https://www.naukri.com/\"\n",
    "driver.get(url)\n",
    "time.sleep(6)\n",
    "\n",
    "# entering Data into Search Bars:-\n",
    "\n",
    "search_field_designation=driver.find_element_by_id(\"qsb-keyword-sugg\") \n",
    "search_field_designation.send_keys(\"Data Scientist\")\n",
    "\n",
    "# clicking the search button:-\n",
    "\n",
    "search_button=driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
    "search_button.click()\n",
    "\n",
    "\n",
    "# creating empty lists for scraping data:-\n",
    "\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]\n",
    "\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "#finding the delhi/ncr check box:-\n",
    "\n",
    "loc=driver.find_element_by_xpath(\"/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[2]/div[2]/div[2]/label/p\")\n",
    "loc.click()\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "# finding the salary check box:-\n",
    "\n",
    "slry_box = driver.find_element_by_xpath(\"/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[3]/div[2]/div[2]/label/p\")\n",
    "slry_box.click()\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "#scraping the job-titles:-\n",
    "\n",
    "titles=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "for i in titles:\n",
    "    if i.text is None :\n",
    "        job_title.append(\"--\") \n",
    "    else:\n",
    "        job_title.append(i.text)\n",
    "        \n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "#scraping the job-location:-\n",
    "\n",
    "locations=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span[1]\")\n",
    "for i in locations:\n",
    "    if i.text is None :\n",
    "        job_location.append(\"--\") \n",
    "    else:\n",
    "        job_location.append(i.text)\n",
    "        \n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "#scraping the company_name:-\n",
    "\n",
    "companies=driver.find_elements_by_xpath(\"//div[@class='mt-7 companyInfo subheading lh16']/a\")\n",
    "for i in companies:\n",
    "    if i.text is None :\n",
    "        company_name.append(\"--\") \n",
    "    else:\n",
    "        company_name.append(i.text)\n",
    "        \n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "#scraping the experience_required:-\n",
    "\n",
    "experience=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span[1]\")\n",
    "for i in experience:\n",
    "    if i.text is None :\n",
    "            experience_required.append(\"--\") \n",
    "    else:\n",
    "            experience_required.append(i.text)\n",
    "            \n",
    "time.sleep(3)\n",
    "\n",
    " # creating the dataframe from the scraped data and taking only first 10 jobs:-\n",
    "    \n",
    "Delhi_NCR_Jobs=pd.DataFrame({\"job_title\":job_title[0:10],\"experience_required\":experience_required[0:10],\"company_name\":company_name[0:10],\n",
    "                 \"job_location\":job_location[0:10]})\n",
    "Delhi_NCR_Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4: Write a python program to scrape data for first 10 job results for Data scientist\n",
    "Designation in Noida location. You have to scrape company_name, No. of days\n",
    "ago when job was posted, Rating of the company.\n",
    "This task will be done in following steps:\n",
    "1. first get the webpage https://www.glassdoor.co.in/index.htm\n",
    "2. Enter “Data Scientist” in “Job Title,Keyword,Company” field and enter “Noida”\n",
    "in “location” field.\n",
    "3. Then click the search button. You will land up in the below page:\n",
    "4. Then scrape the data for the first 10 jobs results you get in the above shown\n",
    "page.\n",
    "WEB SCRAPING ASSIGNMENT-2\n",
    ".\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Edge(r\"C:\\Users\\Akash\\Downloads\\msedgedriver.exe\")\n",
    "time.sleep(4)\n",
    "\n",
    "url = \"https://www.glassdoor.co.in/index.htm\"\n",
    "driver.get(url)\n",
    "\n",
    "# Entering the Login Credentials and logged in using Facebook on Glassdoor website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_name</th>\n",
       "      <th>company_ratings</th>\n",
       "      <th>days_ago</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FE Fundinfo</td>\n",
       "      <td>4.5</td>\n",
       "      <td>17d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PayPal</td>\n",
       "      <td>4.3</td>\n",
       "      <td>12d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Siemens Technology and Services Private Limited</td>\n",
       "      <td>4.1</td>\n",
       "      <td>15d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PayPal</td>\n",
       "      <td>4.3</td>\n",
       "      <td>12d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Applied Materials Inc.</td>\n",
       "      <td>4.0</td>\n",
       "      <td>23d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Springer Nature</td>\n",
       "      <td>3.6</td>\n",
       "      <td>9d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MakeMyTrip</td>\n",
       "      <td>4.3</td>\n",
       "      <td>15d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Microsoft</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AlphaSense</td>\n",
       "      <td>4.3</td>\n",
       "      <td>15d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Tata Insights and Quants</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3d</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      company_name company_ratings days_ago\n",
       "0                                      FE Fundinfo             4.5      17d\n",
       "1                                           PayPal             4.3      12d\n",
       "2  Siemens Technology and Services Private Limited             4.1      15d\n",
       "3                                           PayPal             4.3      12d\n",
       "4                           Applied Materials Inc.             4.0      23d\n",
       "5                                  Springer Nature             3.6       9d\n",
       "6                                       MakeMyTrip             4.3      15d\n",
       "7                                        Microsoft             4.4       1d\n",
       "8                                       AlphaSense             4.3      15d\n",
       "9                         Tata Insights and Quants             3.8       3d"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entering Data into Search Bars:-\n",
    "\n",
    "search_field_designation=driver.find_element_by_xpath(\"//div[@class='d-flex flex-row align-items-center']//div[1]//div[1]//input\") \n",
    "search_field_designation.send_keys(\"Data Scientist\")\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "search_field_location=driver.find_element_by_xpath(\"//div[@class='d-flex flex-row align-items-center']//div[3]//div[1]//input\")\n",
    "search_field_location.clear() \n",
    "search_field_location.send_keys(\"Noida\")\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "# clicking the search button:-\n",
    "\n",
    "search_button=driver.find_element_by_xpath(\"//button[@class='gd-ui-button ml-std col-auto SearchStyles__newSearchButton css-iixdfr']\")\n",
    "search_button.click()\n",
    "\n",
    "\n",
    "# creating empty lists for scraping data:-\n",
    "\n",
    "company_ratings=[]\n",
    "company_name=[]\n",
    "days_ago=[]\n",
    "\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "# finding the element where company name is present:-\n",
    "\n",
    "companies=driver.find_elements_by_xpath(\"//div[@class='d-flex justify-content-between align-items-start']/a\")\n",
    "for i in companies:\n",
    "    if i.text is None :\n",
    "        company_name.append(\"--\") \n",
    "    else:\n",
    "        company_name.append(i.text)\n",
    "\n",
    "        \n",
    "time.sleep(3)        \n",
    "\n",
    "# finding the element where ratings of the company  is present:-\n",
    "\n",
    "ratings=driver.find_elements_by_xpath(\"//span[@class='css-19pjha7 e1cjmv6j1']\")\n",
    "for i in ratings:\n",
    "    if i.text is None :\n",
    "        company_ratings.append(\"--\") \n",
    "    else:\n",
    "        company_ratings.append(i.text)\n",
    "        \n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "# finding the element where No. of days ago when job was posted is present:-\n",
    "\n",
    "days=driver.find_elements_by_xpath(\"//div[@class='d-flex align-items-end pl-std css-mi55ob']\")\n",
    "for i in days:\n",
    "    if i.text is None :\n",
    "        days_ago.append(\"--\") \n",
    "    else:\n",
    "        days_ago.append(i.text)\n",
    "        \n",
    "        \n",
    "time.sleep(3)        \n",
    "\n",
    " # creating the dataframe from the scraped data and taking only first 10 jobs\n",
    "Noida_Jobs=pd.DataFrame({\"company_name\":company_name[0:10],\"company_ratings\":company_ratings[0:10],\"days_ago\":days_ago[0:10]})\n",
    "Noida_Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Q5: Write a python program to scrape the salary data for Data Scientist designation\n",
    "in Noida location.\n",
    "You have to scrape Company name, Number of salaries, Average salary, Min\n",
    "salary, Max Salary.\n",
    "The above task will be, done as shown in the below steps:\n",
    "1. first get the webpage https://www.glassdoor.co.in/Salaries/index.htm\n",
    "2. Enter “Data Scientist” in Job title field and “Noida” in location field.\n",
    "3. Click the search button.\n",
    "4. After that you will land on the below page\n",
    "You have to scrape whole data from this webpage\n",
    "5. Scrape data for first 10 companies. Scrape the min salary, max salary, company\n",
    "name, Average salary and rating of the company.\n",
    "6.Store the data in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Edge(r\"C:\\Users\\Akash\\Downloads\\msedgedriver.exe\")\n",
    "time.sleep(4)\n",
    "\n",
    "url = \"https://www.glassdoor.co.in/index.htm\"\n",
    "driver.get(url)\n",
    "\n",
    "# Entering the Login Credentials and logged in using Facebook on Glassdoor website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_name</th>\n",
       "      <th>min_salaries</th>\n",
       "      <th>max_salaries</th>\n",
       "      <th>average_salaries</th>\n",
       "      <th>no_of_salaries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [company_name, min_salaries, max_salaries, average_salaries, no_of_salaries]\n",
       "Index: []"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entering Data into Search Bars:-\n",
    "\n",
    "search_field_designation=driver.find_element_by_xpath(\"//div[@class='d-flex flex-row align-items-center']//div[1]//div[1]//input\") \n",
    "search_field_designation.send_keys(\"Data Scientist\")\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "# clearing job location search_bar:-\n",
    "\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "for i in range(9):\n",
    "    driver.find_element_by_xpath(\"//div[@class='d-flex flex-row align-items-center']//div[3]//div[1]//input\").send_keys(Keys.BACK_SPACE)\n",
    "\n",
    "#location search bar:-\n",
    "\n",
    "search_field_location=driver.find_element_by_xpath(\"//div[@class='d-flex flex-row align-items-center']//div[3]//div[1]//input\")  \n",
    "search_field_location.send_keys(\"Noida\")\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "# Select salary option:-\n",
    "\n",
    "option = driver.find_element_by_xpath(\"//div[@class='selectedLabel']\")\n",
    "option.click()\n",
    "time.sleep(2)\n",
    "\n",
    "salary_option = driver.find_element_by_xpath(\"//div[@class='dropDownOptionsContainer']//ul//li[3]\")\n",
    "salary_option.click()\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "# clicking the search button:-\n",
    "\n",
    "search_button=driver.find_element_by_xpath(\"//button[@class='gd-ui-button ml-std col-auto SearchStyles__newSearchButton css-iixdfr']\")\n",
    "search_button.click()\n",
    "\n",
    "# creating empty lists for scraping data:-\n",
    "\n",
    "company_name=[]\n",
    "min_salaries=[]\n",
    "max_salaries=[]\n",
    "average_salaries=[]\n",
    "no_of_salaries=[]\n",
    "\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "# finding the element where company_name is present:-\n",
    "\n",
    "company=driver.find_elements_by_xpath(\"//div[@data-test='job-info']/p[2]\")\n",
    "for i in company:\n",
    "    if i.text is None :\n",
    "        company_name.append(\"--\")      \n",
    "    else:\n",
    "        company_name.append(i.text)\n",
    "        \n",
    "time.sleep(3)       \n",
    "\n",
    "# finding the element where min salary is present:-\n",
    "\n",
    "min_salary = driver.find_elements_by_xpath(\"//div[@class='common__RangeBarStyle__values d-flex justify-content-between ']//span[1]\")\n",
    "for i in min_salary:\n",
    "    if i.text is None:\n",
    "        min_salaries.append(\"--\")\n",
    "    else:\n",
    "        min_salaries.append(i.text)\n",
    "        \n",
    "time.sleep(3) \n",
    "\n",
    "# finding the element where max salary is present:-\n",
    "\n",
    "max_salary=driver.find_elements_by_xpath(\"//div[@class='common__RangeBarStyle__values d-flex justify-content-between ']/span[2]\")\n",
    "for i in max_salary:\n",
    "    if i.text is None :\n",
    "        max_salaries.append(\"--\") \n",
    "    else:\n",
    "        max_salaries.append(i.text)\n",
    "        \n",
    "time.sleep(3)   \n",
    "\n",
    "# finding the element where average salary is present:-\n",
    "\n",
    "average_salary=driver.find_elements_by_xpath(\"//div[@class='col-2 d-none d-md-flex flex-row justify-content-end']/strong\")\n",
    "for i in average_salary:\n",
    "    if i.text is None :\n",
    "        average_salaries.append(\"--\") \n",
    "    else:\n",
    "        average_salaries.append(i.text)\n",
    "        \n",
    "time.sleep(3)     \n",
    "\n",
    "# finding the element where no_of_salary is present:-\n",
    "\n",
    "no_of_salary=driver.find_elements_by_xpath(\"//p[@class='css-1uyte9r css-1kuy7z7 m-0 ']\")\n",
    "for i in no_of_salary:\n",
    "    if i.text is None :\n",
    "        no_of_salaries.append(\"--\") \n",
    "    else:\n",
    "        no_of_salaries.append(i.text)\n",
    "        \n",
    "time.sleep(3)  \n",
    "        \n",
    " # creating the dataframe from the scraped data:-\n",
    "\n",
    "Jobs_DS=pd.DataFrame({\"company_name\":company_name,\"min_salaries\":min_salaries,\"max_salaries\":max_salaries,\n",
    "                 \"average_salaries\":average_salaries,\"no_of_salaries\":no_of_salaries})\n",
    "Jobs_DS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Q6 : Scrape data of first 100 sunglasses listings on flipkart.com. You have to\n",
    "scrape four attributes:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. Discount \n",
    "To scrape \n",
    "the data you have to go through following steps:\n",
    "1. Go to flipkart webpage by url https://www.flipkart.com/\n",
    "2. Enter “sunglasses” in the search field where “search for products, brands and\n",
    "more” is written and click the search icon\n",
    "3. after that you will reach to a webpage having a lot of sunglasses. From this page\n",
    "you can scrap the required data as usual.\n",
    "4. after scraping data from the first page, go to the “Next” Button at the bottom of\n",
    "the page , then click on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Edge(r\"C:\\Users\\Akash\\Downloads\\msedgedriver.exe\")\n",
    "time.sleep(4)\n",
    "\n",
    "url = \"https://www.flipkart.com/\"\n",
    "driver.get(url)\n",
    "\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LIZA ANGEL</td>\n",
       "      <td>Polarized, UV Protection Round Sunglasses (49)</td>\n",
       "      <td>₹233</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>UV Protection, Polarized Wayfarer Sunglasses (56)</td>\n",
       "      <td>₹664</td>\n",
       "      <td>66% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Aviator Sunglasses (54)</td>\n",
       "      <td>₹459</td>\n",
       "      <td>48% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>Mirrored, UV Protection Wayfarer Sunglasses (F...</td>\n",
       "      <td>₹250</td>\n",
       "      <td>84% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kingsunglasses</td>\n",
       "      <td>Mirrored, UV Protection Rectangular Sunglasses...</td>\n",
       "      <td>₹299</td>\n",
       "      <td>88% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>AISLIN</td>\n",
       "      <td>UV Protection, Night Vision, Riding Glasses Av...</td>\n",
       "      <td>₹825</td>\n",
       "      <td>79% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>Gradient, UV Protection Wayfarer Sunglasses (F...</td>\n",
       "      <td>₹976</td>\n",
       "      <td>₹323 off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹677</td>\n",
       "      <td>₹222 off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Round Sunglasses (52)</td>\n",
       "      <td>₹529</td>\n",
       "      <td>41% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>GANSTA</td>\n",
       "      <td>UV Protection, Polarized Aviator Sunglasses (60)</td>\n",
       "      <td>₹292</td>\n",
       "      <td>85% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Brand                                        Description Price  \\\n",
       "0       LIZA ANGEL     Polarized, UV Protection Round Sunglasses (49)  ₹233   \n",
       "1        ROYAL SON  UV Protection, Polarized Wayfarer Sunglasses (56)  ₹664   \n",
       "2         Fastrack              UV Protection Aviator Sunglasses (54)  ₹459   \n",
       "3           PIRASO  Mirrored, UV Protection Wayfarer Sunglasses (F...  ₹250   \n",
       "4   kingsunglasses  Mirrored, UV Protection Rectangular Sunglasses...  ₹299   \n",
       "..             ...                                                ...   ...   \n",
       "95          AISLIN  UV Protection, Night Vision, Riding Glasses Av...  ₹825   \n",
       "96        Fastrack  Gradient, UV Protection Wayfarer Sunglasses (F...  ₹976   \n",
       "97        Fastrack      UV Protection Wayfarer Sunglasses (Free Size)  ₹677   \n",
       "98        Fastrack                UV Protection Round Sunglasses (52)  ₹529   \n",
       "99          GANSTA   UV Protection, Polarized Aviator Sunglasses (60)  ₹292   \n",
       "\n",
       "    Discount  \n",
       "0    70% off  \n",
       "1    66% off  \n",
       "2    48% off  \n",
       "3    84% off  \n",
       "4    88% off  \n",
       "..       ...  \n",
       "95   79% off  \n",
       "96  ₹323 off  \n",
       "97  ₹222 off  \n",
       "98   41% off  \n",
       "99   85% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#locating the search bar:-\n",
    "\n",
    "search_bar=driver.find_element_by_class_name(\"_3704LK\")\n",
    "search_bar.send_keys('sunglasses')\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "#locating the button and clicking it to search for sunglasses:-\n",
    "\n",
    "button=driver.find_element_by_class_name('L0Z3Pu')\n",
    "button.click()\n",
    "\n",
    "\n",
    "#creating the empty list:-\n",
    "\n",
    "brand=[]\n",
    "description=[]\n",
    "price=[]\n",
    "discount=[]\n",
    "\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "#scrapping the required details:-\n",
    "\n",
    "start=0\n",
    "end=4\n",
    "for page in range(start,end):#for loop for scrapping 4 page\n",
    "    brands=driver.find_elements_by_class_name('_2WkVRV')#scraping brands name by class name='_2WkVRV'\n",
    "    for i in brands:\n",
    "        brand.append(i.text)#appending the text in Brand list\n",
    "    desc=driver.find_elements_by_xpath('//a[@class=\"IRpwTa\"]')#scraping description from the xpath\n",
    "    for i in desc:\n",
    "        description.append(i.text)#appending the description in list\n",
    "    prices=driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")# scraping the price from the xpath\n",
    "    for i in prices:\n",
    "        price.append(i.text)\n",
    "    disc=driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']//span\")# scraping the discount from the xpath\n",
    "    for i in disc:\n",
    "        discount.append(i.text)\n",
    "    nxt_button=driver.find_elements_by_xpath(\"//a[@class='_1LKTO3']\")#scraping the list of buttons from the page\n",
    "    try:\n",
    "        driver.get(nxt_button[1].get_attribute('href'))#getting the link from the list for next page\n",
    "    except:\n",
    "        driver.get(nxt_button[0].get_attribute('href'))\n",
    "\n",
    "time.sleep(3)   \n",
    "\n",
    "#creating a dataframe:-\n",
    "\n",
    "Flipkart=pd.DataFrame({'Brand':brand[:100],\n",
    "                'Description':description[:100],\n",
    "                'Price':price[:100],\n",
    "                'Discount':discount[:100]})\n",
    "\n",
    "Flipkart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Q7: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to \n",
    "go the link: https://www.flipkart.com/apple-iphone-11-black-64-gb-includes\u0002earpods-power\u0002adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace.\n",
    "you have to scrape the below mention attributes.\n",
    "These are \n",
    "1. Rating \n",
    "2. Review_summary \n",
    "3. Full review\n",
    "You have to scrape this data for first 100 reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Stars</th>\n",
       "      <th>Short Review</th>\n",
       "      <th>Full Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Value for money❤️❤️\\nIts awesome mobile phone ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Best budget Iphone till date ❤️ go for it guys...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Iphone is just awesome.. battery backup is ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>What a camera .....just awesome ..you can feel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>It’s been almost a month since I have been usi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>4</td>\n",
       "      <td>Good choice</td>\n",
       "      <td>So far it’s been an AMAZING experience coming ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>i11 is worthy to buy, too much happy with the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>iphone 11 is a very good phone to buy only if ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>It’s a must buy who is looking for an upgrade ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Number of Stars        Short Review  \\\n",
       "0                5    Perfect product!   \n",
       "1                5   Worth every penny   \n",
       "2                5    Perfect product!   \n",
       "3                5  Highly recommended   \n",
       "4                5   Worth every penny   \n",
       "..             ...                 ...   \n",
       "95               4         Good choice   \n",
       "96               5      Simply awesome   \n",
       "97               5   Worth every penny   \n",
       "98               5  Highly recommended   \n",
       "99               5    Perfect product!   \n",
       "\n",
       "                                          Full Review  \n",
       "0   Value for money❤️❤️\\nIts awesome mobile phone ...  \n",
       "1   Best budget Iphone till date ❤️ go for it guys...  \n",
       "2   Iphone is just awesome.. battery backup is ver...  \n",
       "3   What a camera .....just awesome ..you can feel...  \n",
       "4   It’s been almost a month since I have been usi...  \n",
       "..                                                ...  \n",
       "95  So far it’s been an AMAZING experience coming ...  \n",
       "96  Really satisfied with the Product I received.....  \n",
       "97  i11 is worthy to buy, too much happy with the ...  \n",
       "98  iphone 11 is a very good phone to buy only if ...  \n",
       "99  It’s a must buy who is looking for an upgrade ...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver=webdriver.Edge(r\"C:\\Users\\Akash\\Downloads\\msedgedriver.exe\")\n",
    "time.sleep(4)\n",
    "\n",
    "url = \"https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace=FLIPKART\"\n",
    "driver.get(url)\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "# Creating empty list:-\n",
    "\n",
    "urls=[]\n",
    "short_review=[]\n",
    "complete_review=[]\n",
    "stars=[]\n",
    "\n",
    "time.sleep(4)\n",
    "\n",
    "# Taking 10 pages into consideration using for loop\n",
    "for i in range(10):\n",
    "    url=driver.find_element_by_xpath(\"//a[@class='ge-49M']\").get_attribute('href')\n",
    "    driver.get(url)\n",
    "\n",
    "    for j in driver.find_elements_by_xpath(\"//div[@class='_3LWZlK _1BLPMq']\"):\n",
    "        stars.append(j.text)\n",
    "    \n",
    "    for k in driver.find_elements_by_xpath(\"//p[@class='_2-N8zT']\"):\n",
    "        short_review.append(k.text)\n",
    "\n",
    "    for l in driver.find_elements_by_xpath(\"//div[@class='t-ZTKy']/div/div\"):\n",
    "        complete_review.append(l.text)\n",
    "        \n",
    "        \n",
    "        \n",
    "# Combining all the lists into a single dataframe:-\n",
    "\n",
    "Iphone11=pd.DataFrame({'Number of Stars': stars,\n",
    "                'Short Review': short_review,\n",
    "               'Full Review': complete_review})\n",
    "Iphone11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Q8:Scrape data for first 100 sneakers you find when you visit flipkart.comand search for “sneakers” in the search field.You have to scrape 4 attributes of each sneaker :\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. discount %\n",
    "Also note that all the steps required during scraping should be done through code only and not manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3SIX5</td>\n",
       "      <td>Rigel IDP Sneakers For Men  (Black)</td>\n",
       "      <td>₹689</td>\n",
       "      <td>72% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Extoes</td>\n",
       "      <td>Sneakers For Men  (Black)</td>\n",
       "      <td>₹499</td>\n",
       "      <td>50% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Robbie jones</td>\n",
       "      <td>Puma Flex Renew Sneakers For Men  (Black)</td>\n",
       "      <td>₹379</td>\n",
       "      <td>62% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CALCADOS</td>\n",
       "      <td>Combo of 5 Multicolor Casual Sneakers Shoes Fo...</td>\n",
       "      <td>₹748</td>\n",
       "      <td>62% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shoes Bank</td>\n",
       "      <td>Casual , Partywear Sneakers Shoes For Men's An...</td>\n",
       "      <td>₹349</td>\n",
       "      <td>65% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Birde</td>\n",
       "      <td>Combo Pack of 5 Casual Shoes Loafers Sneakers ...</td>\n",
       "      <td>₹588</td>\n",
       "      <td>77% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Jack Diamond</td>\n",
       "      <td>Street Smart Sneakers For Men  (White, Blue)</td>\n",
       "      <td>₹630</td>\n",
       "      <td>52% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>SHOEFLY</td>\n",
       "      <td>Dexster Slip On IDP Sneakers For Men  (Blue)</td>\n",
       "      <td>₹498</td>\n",
       "      <td>65% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>Trendy Sneakers For Men  (Red)</td>\n",
       "      <td>₹448</td>\n",
       "      <td>15% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>U.S. POLO ASSN.</td>\n",
       "      <td>LEONEL Sneakers For Men  (White)</td>\n",
       "      <td>₹3,999</td>\n",
       "      <td>55% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Brand                                        Description  \\\n",
       "0             3SIX5                Rigel IDP Sneakers For Men  (Black)   \n",
       "1            Extoes                          Sneakers For Men  (Black)   \n",
       "2      Robbie jones          Puma Flex Renew Sneakers For Men  (Black)   \n",
       "3          CALCADOS  Combo of 5 Multicolor Casual Sneakers Shoes Fo...   \n",
       "4        Shoes Bank  Casual , Partywear Sneakers Shoes For Men's An...   \n",
       "..              ...                                                ...   \n",
       "95            Birde  Combo Pack of 5 Casual Shoes Loafers Sneakers ...   \n",
       "96     Jack Diamond       Street Smart Sneakers For Men  (White, Blue)   \n",
       "97          SHOEFLY       Dexster Slip On IDP Sneakers For Men  (Blue)   \n",
       "98           Chevit                     Trendy Sneakers For Men  (Red)   \n",
       "99  U.S. POLO ASSN.                   LEONEL Sneakers For Men  (White)   \n",
       "\n",
       "     Price Discount  \n",
       "0     ₹689  72% off  \n",
       "1     ₹499  50% off  \n",
       "2     ₹379  62% off  \n",
       "3     ₹748  62% off  \n",
       "4     ₹349  65% off  \n",
       "..     ...      ...  \n",
       "95    ₹588  77% off  \n",
       "96    ₹630  52% off  \n",
       "97    ₹498  65% off  \n",
       "98    ₹448  15% off  \n",
       "99  ₹3,999  55% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver=webdriver.Edge(r\"C:\\Users\\Akash\\Downloads\\msedgedriver.exe\")\n",
    "time.sleep(4)\n",
    "\n",
    "url = \"https://www.flipkart.com/\"\n",
    "driver.get(url)\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "log_in_pop_up = driver.find_element_by_xpath(\"//button[@class='_2KpZ6l _2doB4z']\")\n",
    "log_in_pop_up.click()\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "# locating the search bar:-\n",
    "\n",
    "search_bar=driver.find_element_by_class_name(\"_3704LK\")\n",
    "search_bar.clear()\n",
    "search_bar.send_keys('sneakers')\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "# locating the button and clicking it to search for sneakers:-\n",
    "\n",
    "button=driver.find_element_by_class_name('L0Z3Pu')\n",
    "button.click()\n",
    "\n",
    "\n",
    "# creating the empty list:-\n",
    "\n",
    "brand=[]\n",
    "description=[]\n",
    "price=[]\n",
    "discount=[]\n",
    "\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "# scrapping the required details:-\n",
    "\n",
    "start=0\n",
    "end=4\n",
    "for page in range(start,end):#for loop for scrapping 4 page\n",
    "    brands=driver.find_elements_by_class_name('_2WkVRV')#scraping brands name by class name='_2WkVRV'\n",
    "    for i in brands:\n",
    "        brand.append(i.text)#appending the text in Brand list\n",
    "    prices=driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")# scraping the price from the xpath\n",
    "    for i in prices:\n",
    "        price.append(i.text)\n",
    "    disc=driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']//span\")# scraping the discount from the xpath\n",
    "    for i in disc:\n",
    "        discount.append(i.text)\n",
    "    nxt_button=driver.find_elements_by_xpath(\"//a[@class='_1LKTO3']\")#scraping the list of buttons from the page\n",
    "    try:\n",
    "        driver.get(nxt_button[1].get_attribute('href'))#getting the link from the list for next page\n",
    "    except:\n",
    "        driver.get(nxt_button[0].get_attribute('href'))\n",
    "        \n",
    "        \n",
    "        \n",
    "time.sleep(2)\n",
    "\n",
    "# Since in some records not getting description so try from inside of urls\n",
    "urls = []\n",
    "\n",
    "for page in range(0,4):#for loop for scrapping 4 page\n",
    "    \n",
    "    product_url = driver.find_elements_by_xpath(\"//a[@class='_2UzuFa']\")\n",
    "    for i in product_url:\n",
    "        urls.append(i.get_attribute('href'))\n",
    "    \n",
    "    nxt_button=driver.find_elements_by_xpath(\"//a[@class='_1LKTO3']\")#scraping the list of buttons from the page\n",
    "    try:\n",
    "        driver.get(nxt_button[1].get_attribute('href'))#getting the link from the list for next page\n",
    "    except:\n",
    "        driver.get(nxt_button[0].get_attribute('href'))\n",
    "        \n",
    "time.sleep(2)\n",
    "\n",
    "for i in urls:\n",
    "    driver.get(i)\n",
    "    desc=driver.find_elements_by_xpath('//span[@class=\"B_NuCI\"]')#scraping description from the xpath\n",
    "    for i in desc:\n",
    "        description.append(i.text)#appending the description in list\n",
    "time.sleep(2)        \n",
    "time.sleep(3)\n",
    "\n",
    "#creating a dataframe:-\n",
    "\n",
    "Sneakers=pd.DataFrame({'Brand':brand[:100],\n",
    "                'Description':description[:100],\n",
    "                'Price':price[:100],\n",
    "                'Discount':discount[:100]})\n",
    "\n",
    "Sneakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q9.\"https://www.myntra.com/shoes\". \n",
    "Set price filter \"Rs 6649 to Rs 13099\" and color filter to \"Black\" and then scrap 100 shoes data. The data should include \"Brand\" of shoes, shoe short-description and price. Please not: Everything should done through code even the filtering for sneakers as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Short-description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Men IGNITE Dual Running Shoes</td>\n",
       "      <td>Rs. 3499Rs. 6999(50% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Provogue</td>\n",
       "      <td>Men Knitted Upper Running Sport Shoes</td>\n",
       "      <td>Rs. 679Rs. 3395(80% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>REFOAM</td>\n",
       "      <td>Men Running Shoes</td>\n",
       "      <td>Rs. 909Rs. 3249(72% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Unisex LEBRON XVIII Basketball</td>\n",
       "      <td>Rs. 17595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Duke</td>\n",
       "      <td>Men Loafers</td>\n",
       "      <td>Rs. 918Rs. 2295(60% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>mr.wonker</td>\n",
       "      <td>Men Fly Sneakers</td>\n",
       "      <td>Rs. 665Rs. 3329(80% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Men Dart IDP Sneakers</td>\n",
       "      <td>Rs. 1599Rs. 3999(60% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>mr.wonker</td>\n",
       "      <td>Men Textured Leather Driving Shoes</td>\n",
       "      <td>Rs. 665Rs. 3329(80% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>U.S. Polo Assn.</td>\n",
       "      <td>Men Solid Sneakers</td>\n",
       "      <td>Rs. 1329Rs. 3799(65% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>HIGHLANDER</td>\n",
       "      <td>Men Skate Street Sneakers</td>\n",
       "      <td>Rs. 696Rs. 1990(65% OFF)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Brand                      Short-description  \\\n",
       "0              Puma          Men IGNITE Dual Running Shoes   \n",
       "1          Provogue  Men Knitted Upper Running Sport Shoes   \n",
       "2            REFOAM                      Men Running Shoes   \n",
       "3              Nike         Unisex LEBRON XVIII Basketball   \n",
       "4              Duke                            Men Loafers   \n",
       "..              ...                                    ...   \n",
       "95        mr.wonker                       Men Fly Sneakers   \n",
       "96             Puma                  Men Dart IDP Sneakers   \n",
       "97        mr.wonker     Men Textured Leather Driving Shoes   \n",
       "98  U.S. Polo Assn.                     Men Solid Sneakers   \n",
       "99       HIGHLANDER              Men Skate Street Sneakers   \n",
       "\n",
       "                        Price  \n",
       "0   Rs. 3499Rs. 6999(50% OFF)  \n",
       "1    Rs. 679Rs. 3395(80% OFF)  \n",
       "2    Rs. 909Rs. 3249(72% OFF)  \n",
       "3                   Rs. 17595  \n",
       "4    Rs. 918Rs. 2295(60% OFF)  \n",
       "..                        ...  \n",
       "95   Rs. 665Rs. 3329(80% OFF)  \n",
       "96  Rs. 1599Rs. 3999(60% OFF)  \n",
       "97   Rs. 665Rs. 3329(80% OFF)  \n",
       "98  Rs. 1329Rs. 3799(65% OFF)  \n",
       "99   Rs. 696Rs. 1990(65% OFF)  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver=webdriver.Edge(r\"C:\\Users\\Akash\\Downloads\\msedgedriver.exe\")\n",
    "time.sleep(4)\n",
    "\n",
    "url = \"https://www.myntra.com/shoes%22\"\n",
    "driver.get(url)\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "#clicking on price filter:-\n",
    "\n",
    "price_button = driver.find_element_by_xpath(\"/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[5]/ul/li[2]/label/div\")\n",
    "price_button.click()\n",
    "\n",
    "#clicking on black color filter:-\n",
    "\n",
    "black_color_button = driver.find_element_by_xpath(\"/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[6]/ul/li[1]/label/div\")\n",
    "black_color_button.click()\n",
    "\n",
    "\n",
    "\n",
    "#creating empty lists:-\n",
    "\n",
    "shoe_names=[]\n",
    "s_desc=[]\n",
    "short_desc=[]\n",
    "price=[]\n",
    "page_urls = []\n",
    "\n",
    "time.sleep(4)\n",
    "\n",
    "# scrape next pages urls:-\n",
    "\n",
    "nxt_page = driver.find_elements_by_xpath(\"//li[@class='pagination-number']/a\")\n",
    "for i in nxt_page:\n",
    "    page_urls.append(i.get_attribute('href'))\n",
    "    \n",
    "\n",
    "for url in page_urls[:3]:\n",
    "    driver.get(url)\n",
    "    Names=driver.find_elements_by_xpath(\"//div[@class='product-productMetaInfo']/h3\")  #for scrapping shoe brand names\n",
    "    for i in Names:\n",
    "        shoe_names.append(i.text)\n",
    "    \n",
    "    desc=driver.find_elements_by_xpath(\"//div[@class='product-productMetaInfo']/h4\") #for scrapping shoe short-description\n",
    "    for i in desc:\n",
    "        s_desc.append(i.text)\n",
    "    for j in range(0,len(s_desc),2):\n",
    "        short_desc.append(s_desc[j])\n",
    "    \n",
    "    rs=driver.find_elements_by_xpath(\"//div[@class='product-price']\")  #for scrapping shoe prices\n",
    "    for i in rs:\n",
    "        price.append(i.text)    \n",
    "        \n",
    "Shoes=pd.DataFrame({'Brand': shoe_names[:100],'Short-description': short_desc[:100],'Price': price[:100]})\n",
    "Shoes  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Q10:  Go to webpage https://www.amazon.in/Enter “Laptop” in the search field and then click the search icon.Then set CPU Type filter to “Intel Core i7” and “Intel Core i9”\n",
    "After setting the filters scrape first 10 laptops data.You have to scrape 3 attributes for each laptop:\n",
    "1. title\n",
    "2. Ratings\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Price</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HP Pavilion x360 (2021) 14\" (35.56cms) FHD Tou...</td>\n",
       "      <td>78,903</td>\n",
       "      <td>3.9 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HP Pavilion (2021) Thin &amp; Light 11th Gen Core ...</td>\n",
       "      <td>84,990</td>\n",
       "      <td>4.5 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(Renewed) Dell Intel Core i7 4th Gen 14 Inch(3...</td>\n",
       "      <td>46,999</td>\n",
       "      <td>NO rating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mi Notebook Horizon Edition 14 Intel Core i7-1...</td>\n",
       "      <td>59,999</td>\n",
       "      <td>4.4 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dell Inspiron 5410 14\" FHD Touch Display 2in1 ...</td>\n",
       "      <td>91,990</td>\n",
       "      <td>4.5 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(Renewed) Dell Intel Core i7 4th Gen 14 Inch(3...</td>\n",
       "      <td>54,999</td>\n",
       "      <td>NO rating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HP Pavilion Gaming 10th Gen Intel Core i7 Proc...</td>\n",
       "      <td>86,990</td>\n",
       "      <td>4.2 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HP Pavilion Gaming(2021) 10th Gen Intel Core i...</td>\n",
       "      <td>91,990</td>\n",
       "      <td>3 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(Renewed) Dell Intel Core i7 4th Gen 14 Inch(3...</td>\n",
       "      <td>46,999</td>\n",
       "      <td>NO rating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(Renewed) Dell XPS Intel 8th Gen Core i7 13.3-...</td>\n",
       "      <td>89,490</td>\n",
       "      <td>NO rating</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title   Price       Ratings\n",
       "0  HP Pavilion x360 (2021) 14\" (35.56cms) FHD Tou...  78,903  3.9 out of 5\n",
       "1  HP Pavilion (2021) Thin & Light 11th Gen Core ...  84,990  4.5 out of 5\n",
       "2  (Renewed) Dell Intel Core i7 4th Gen 14 Inch(3...  46,999     NO rating\n",
       "3  Mi Notebook Horizon Edition 14 Intel Core i7-1...  59,999  4.4 out of 5\n",
       "4  Dell Inspiron 5410 14\" FHD Touch Display 2in1 ...  91,990  4.5 out of 5\n",
       "5  (Renewed) Dell Intel Core i7 4th Gen 14 Inch(3...  54,999     NO rating\n",
       "6  HP Pavilion Gaming 10th Gen Intel Core i7 Proc...  86,990  4.2 out of 5\n",
       "7  HP Pavilion Gaming(2021) 10th Gen Intel Core i...  91,990    3 out of 5\n",
       "8  (Renewed) Dell Intel Core i7 4th Gen 14 Inch(3...  46,999     NO rating\n",
       "9  (Renewed) Dell XPS Intel 8th Gen Core i7 13.3-...  89,490     NO rating"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver=webdriver.Edge(r\"C:\\Users\\Akash\\Downloads\\msedgedriver.exe\")\n",
    "time.sleep(4)\n",
    "\n",
    "url = \"https://www.amazon.in/ref=nav_logo\"\n",
    "driver.get(url)\n",
    "\n",
    "\n",
    "#creating the empty list:-\n",
    "\n",
    "Title=[]\n",
    "Ratings=[]\n",
    "price=[]\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "#locating the search bar:-\n",
    "\n",
    "search_bar = driver.find_element_by_id(\"twotabsearchtextbox\")    \n",
    "search_bar.clear()                                               \n",
    "search_bar.send_keys(\"laptops\")                                  \n",
    "search_button = driver.find_element_by_xpath('//span[@id=\"nav-search-submit-text\"]')    \n",
    "search_button.click()    \n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "#locating the core i7 filter:-\n",
    "\n",
    "filter_button=driver.find_elements_by_xpath(\"//a[@class='a-link-normal s-navigation-item']/span\")\n",
    "for i in filter_button:\n",
    "    if i.text=='Intel Core i7':\n",
    "        i.click()\n",
    "        break\n",
    "        \n",
    "        \n",
    "#Scrapping Titles:-\n",
    "\n",
    "titles=driver.find_elements_by_xpath(\"//span[@class='a-size-medium a-color-base a-text-normal']\")\n",
    "for i in titles[:10]:\n",
    "    Title.append(i.text)\n",
    "    \n",
    "    \n",
    "#scrapping Price:-\n",
    "\n",
    "prices=driver.find_elements_by_xpath(\"//span[@class='a-price-whole']\")\n",
    "for i in prices[:10]:\n",
    "    price.append(i.text)\n",
    "\n",
    "#locating Ratings:-\n",
    "\n",
    "urls=driver.find_elements_by_xpath(\"//a[@class='a-link-normal a-text-normal']\")#collecting urls of all the laptop\n",
    "UR=[]\n",
    "for i in urls[:10]:\n",
    "    UR.append(i.get_attribute('href'))#getting the url of first 10 laptops\n",
    "for url in UR:#loop for every laptop in the list\n",
    "    driver.get(url)\n",
    "    try:                  #exception handling for nosuchelementexception                                                    #click the rating link found\n",
    "        rating=driver.find_element_by_xpath(\"//span[@class='a-size-base a-nowrap']//span\")#locating the rating\n",
    "        Ratings.append(rating.text)#appending the ratings in Ratings list\n",
    "        \n",
    "    except NoSuchElementException:\n",
    "        Ratings.append(\"NO rating\")#appending the No rating if no rating is there\n",
    "        \n",
    "#creating a dataframe:-\n",
    "\n",
    "Laptop=pd.DataFrame({'Title':Title,\n",
    "                'Price':price,\n",
    "                'Ratings':Ratings})\n",
    "\n",
    "Laptop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
