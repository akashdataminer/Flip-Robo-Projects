{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in c:\\users\\akash\\anaconda3\\lib\\site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from bs4) (4.9.3)\n",
      "Requirement already satisfied: soupsieve>1.2; python_version >= \"3.0\" in c:\\users\\akash\\anaconda3\\lib\\site-packages (from beautifulsoup4->bs4) (2.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\akash\\anaconda3\\lib\\site-packages (2.24.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from requests) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from requests) (1.25.11)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from requests) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from requests) (2.10)\n",
      "Requirement already satisfied: requests_html in c:\\users\\akash\\anaconda3\\lib\\site-packages (0.10.0)\n",
      "Requirement already satisfied: pyquery in c:\\users\\akash\\anaconda3\\lib\\site-packages (from requests_html) (1.4.3)\n",
      "Requirement already satisfied: bs4 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from requests_html) (0.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\akash\\anaconda3\\lib\\site-packages (from requests_html) (2.24.0)\n",
      "Requirement already satisfied: parse in c:\\users\\akash\\anaconda3\\lib\\site-packages (from requests_html) (1.19.0)\n",
      "Requirement already satisfied: fake-useragent in c:\\users\\akash\\anaconda3\\lib\\site-packages (from requests_html) (0.1.11)\n",
      "Requirement already satisfied: pyppeteer>=0.0.14 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from requests_html) (0.2.5)\n",
      "Requirement already satisfied: w3lib in c:\\users\\akash\\anaconda3\\lib\\site-packages (from requests_html) (1.22.0)\n",
      "Requirement already satisfied: cssselect>0.7.9 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from pyquery->requests_html) (1.1.0)\n",
      "Requirement already satisfied: lxml>=2.1 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from pyquery->requests_html) (4.6.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from bs4->requests_html) (4.9.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from requests->requests_html) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from requests->requests_html) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from requests->requests_html) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from requests->requests_html) (1.25.11)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.42.1 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from pyppeteer>=0.0.14->requests_html) (4.50.2)\n",
      "Requirement already satisfied: appdirs<2.0.0,>=1.4.3 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from pyppeteer>=0.0.14->requests_html) (1.4.4)\n",
      "Requirement already satisfied: pyee<9.0.0,>=8.1.0 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from pyppeteer>=0.0.14->requests_html) (8.1.0)\n",
      "Requirement already satisfied: websockets<9.0,>=8.1 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from pyppeteer>=0.0.14->requests_html) (8.1)\n",
      "Requirement already satisfied: six>=1.4.1 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from w3lib->requests_html) (1.15.0)\n",
      "Requirement already satisfied: soupsieve>1.2; python_version >= \"3.0\" in c:\\users\\akash\\anaconda3\\lib\\site-packages (from beautifulsoup4->bs4->requests_html) (2.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install bs4\n",
    "!pip install requests\n",
    "!pip install requests_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries Loaded Successfully!!\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "print(\"Libraries Loaded Successfully!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Q1. Write a python program to display all the header tags from ‘en.wikipedia.org/wiki/Main_Page’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def header(url):\n",
    "    p=requests.get(url)\n",
    "    #p.content\n",
    "    \n",
    "    print(p.status_code)\n",
    "    \n",
    "    s=BeautifulSoup(p.content, \"html.parser\")\n",
    "    \n",
    "    #print(s.prettify())\n",
    "    \n",
    "    h=s.find_all('span', class_=\"mw-headline\")\n",
    "    header=[]\n",
    "    \n",
    "    for i in h:\n",
    "        header.append(i.get_text())\n",
    "    print(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "[\"From today's featured article\", 'Did you know\\xa0...', 'In the news', 'On this day', \"Today's featured picture\", 'Other areas of Wikipedia', \"Wikipedia's sister projects\", 'Wikipedia languages']\n"
     ]
    }
   ],
   "source": [
    "header(\"https://en.wikipedia.org/wiki/Main_Page\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Q2. Write a python program to display IMDB’s Top rated 100 movies’ data (i.e. Name, IMDB rating, Year of release) and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\",None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imdb(url):\n",
    "    p2=requests.get(url)\n",
    "    #p2.content\n",
    "    \n",
    "    print(p2.status_code)\n",
    "    \n",
    "    s2=BeautifulSoup(p2.content, \"html.parser\")\n",
    "    #print(s2.prettify())\n",
    "    \n",
    "    title1=s2.find_all('td', class_='titleColumn')\n",
    "    movie_title=[]\n",
    "    for i in title1:\n",
    "        for j in i.find_all(\"a\"):\n",
    "            movie_title.append(j.text)\n",
    "    \n",
    "    year1=s2.find_all('span', class_='secondaryInfo')\n",
    "    release_year=[]\n",
    "    for i in year1:\n",
    "        release_year.append(i.text)\n",
    "            \n",
    "    rating1=s2.find_all('td', class_='ratingColumn imdbRating')\n",
    "    movie_rating=[]\n",
    "    for i in rating1:\n",
    "        for j in i.find_all(\"strong\"):\n",
    "            movie_rating.append(j.text)\n",
    "            \n",
    "    IMDB_MOVIES=pd.DataFrame()\n",
    "    IMDB_MOVIES[\"Movie_Title\"]=movie_title[0:100]\n",
    "    IMDB_MOVIES[\"Release_Year\"]=release_year[0:100]\n",
    "    IMDB_MOVIES[\"Movie_Ratings\"]=movie_rating[0:100]\n",
    "    \n",
    "    print(IMDB_MOVIES)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "                                          Movie_Title Release_Year  \\\n",
      "0                            The Shawshank Redemption       (1994)   \n",
      "1                                       The Godfather       (1972)   \n",
      "2                              The Godfather: Part II       (1974)   \n",
      "3                                     The Dark Knight       (2008)   \n",
      "4                                        12 Angry Men       (1957)   \n",
      "5                                    Schindler's List       (1993)   \n",
      "6       The Lord of the Rings: The Return of the King       (2003)   \n",
      "7                                        Pulp Fiction       (1994)   \n",
      "8                     Il buono, il brutto, il cattivo       (1966)   \n",
      "9   The Lord of the Rings: The Fellowship of the Ring       (2001)   \n",
      "10                                         Fight Club       (1999)   \n",
      "11                                       Forrest Gump       (1994)   \n",
      "12                                          Inception       (2010)   \n",
      "13              The Lord of the Rings: The Two Towers       (2002)   \n",
      "14     Star Wars: Episode V - The Empire Strikes Back       (1980)   \n",
      "15                                         The Matrix       (1999)   \n",
      "16                                         Goodfellas       (1990)   \n",
      "17                    One Flew Over the Cuckoo's Nest       (1975)   \n",
      "18                               Shichinin no samurai       (1954)   \n",
      "19                                              Se7en       (1995)   \n",
      "20                           The Silence of the Lambs       (1991)   \n",
      "21                                     Cidade de Deus       (2002)   \n",
      "22                              It's a Wonderful Life       (1946)   \n",
      "23                                    La vita è bella       (1997)   \n",
      "24                                          Star Wars       (1977)   \n",
      "25                                Saving Private Ryan       (1998)   \n",
      "26                      Sen to Chihiro no kamikakushi       (2001)   \n",
      "27                                     The Green Mile       (1999)   \n",
      "28                                       Interstellar       (2014)   \n",
      "29                                       Gisaengchung       (2019)   \n",
      "30                                               Léon       (1994)   \n",
      "31                                            Seppuku       (1962)   \n",
      "32                                 The Usual Suspects       (1995)   \n",
      "33                                        The Pianist       (2002)   \n",
      "34                                 Back to the Future       (1985)   \n",
      "35                         Terminator 2: Judgment Day       (1991)   \n",
      "36                                       Modern Times       (1936)   \n",
      "37                                             Psycho       (1960)   \n",
      "38                                      The Lion King       (1994)   \n",
      "39                                 American History X       (1998)   \n",
      "40                                        City Lights       (1931)   \n",
      "41                                          Gladiator       (2000)   \n",
      "42                                           Whiplash       (2014)   \n",
      "43                                       The Departed       (2006)   \n",
      "44                                     Hotaru no haka       (1988)   \n",
      "45                                   The Intouchables       (2011)   \n",
      "46                                       The Prestige       (2006)   \n",
      "47                                         Casablanca       (1942)   \n",
      "48                       Once Upon a Time in the West       (1968)   \n",
      "49                                        Rear Window       (1954)   \n",
      "50                              Nuovo Cinema Paradiso       (1988)   \n",
      "51                                              Alien       (1979)   \n",
      "52                                     Apocalypse Now       (1979)   \n",
      "53                                            Memento       (2000)   \n",
      "54                            Raiders of the Lost Ark       (1981)   \n",
      "55                                 The Great Dictator       (1940)   \n",
      "56                                The Lives of Others       (2006)   \n",
      "57                                   Django Unchained       (2012)   \n",
      "58                                     Paths of Glory       (1957)   \n",
      "59                                       Sunset Blvd.       (1950)   \n",
      "60                                             WALL·E       (2008)   \n",
      "61                                        The Shining       (1980)   \n",
      "62                        Witness for the Prosecution       (1957)   \n",
      "63                             Avengers: Infinity War       (2018)   \n",
      "64                                              Joker       (2019)   \n",
      "65  Dr. Strangelove or: How I Learned to Stop Worr...       (1964)   \n",
      "66                  Spider-Man: Into the Spider-Verse       (2018)   \n",
      "67                                           Oldeuboi       (2003)   \n",
      "68                                      Mononoke-hime       (1997)   \n",
      "69                                           Hamilton       (2020)   \n",
      "70                        Once Upon a Time in America       (1984)   \n",
      "71                                     Kimi no na wa.       (2016)   \n",
      "72                              The Dark Knight Rises       (2012)   \n",
      "73                                             Aliens       (1986)   \n",
      "74                                    Pather Panchali       (1955)   \n",
      "75                                               Coco       (2017)   \n",
      "76                                           Das Boot       (1981)   \n",
      "77                                         Capharnaüm       (2018)   \n",
      "78                                  Tengoku to jigoku       (1963)   \n",
      "79                                  Avengers: Endgame       (2019)   \n",
      "80                                    American Beauty       (1999)   \n",
      "81                                          Toy Story       (1995)   \n",
      "82                                         Braveheart       (1995)   \n",
      "83                                            Amadeus       (1984)   \n",
      "84                                           3 Idiots       (2009)   \n",
      "85                               Inglourious Basterds       (2009)   \n",
      "86                                  Good Will Hunting       (1997)   \n",
      "87         Star Wars: Episode VI - Return of the Jedi       (1983)   \n",
      "88                              2001: A Space Odyssey       (1968)   \n",
      "89                                     Reservoir Dogs       (1992)   \n",
      "90                  M - Eine Stadt sucht einen Mörder       (1931)   \n",
      "91                                   Taare Zameen Par       (2007)   \n",
      "92                                       Citizen Kane       (1941)   \n",
      "93                                            Vertigo       (1958)   \n",
      "94                                Requiem for a Dream       (2000)   \n",
      "95                                             Jagten       (2012)   \n",
      "96                                Singin' in the Rain       (1952)   \n",
      "97                                 North by Northwest       (1959)   \n",
      "98                                       Idi i smotri       (1985)   \n",
      "99              Eternal Sunshine of the Spotless Mind       (2004)   \n",
      "\n",
      "   Movie_Ratings  \n",
      "0            9.2  \n",
      "1            9.1  \n",
      "2            9.0  \n",
      "3            9.0  \n",
      "4            8.9  \n",
      "5            8.9  \n",
      "6            8.9  \n",
      "7            8.8  \n",
      "8            8.8  \n",
      "9            8.8  \n",
      "10           8.8  \n",
      "11           8.7  \n",
      "12           8.7  \n",
      "13           8.7  \n",
      "14           8.7  \n",
      "15           8.6  \n",
      "16           8.6  \n",
      "17           8.6  \n",
      "18           8.6  \n",
      "19           8.6  \n",
      "20           8.6  \n",
      "21           8.6  \n",
      "22           8.6  \n",
      "23           8.6  \n",
      "24           8.6  \n",
      "25           8.5  \n",
      "26           8.5  \n",
      "27           8.5  \n",
      "28           8.5  \n",
      "29           8.5  \n",
      "30           8.5  \n",
      "31           8.5  \n",
      "32           8.5  \n",
      "33           8.5  \n",
      "34           8.5  \n",
      "35           8.5  \n",
      "36           8.5  \n",
      "37           8.5  \n",
      "38           8.5  \n",
      "39           8.5  \n",
      "40           8.5  \n",
      "41           8.5  \n",
      "42           8.5  \n",
      "43           8.5  \n",
      "44           8.5  \n",
      "45           8.5  \n",
      "46           8.5  \n",
      "47           8.4  \n",
      "48           8.4  \n",
      "49           8.4  \n",
      "50           8.4  \n",
      "51           8.4  \n",
      "52           8.4  \n",
      "53           8.4  \n",
      "54           8.4  \n",
      "55           8.4  \n",
      "56           8.4  \n",
      "57           8.4  \n",
      "58           8.4  \n",
      "59           8.4  \n",
      "60           8.4  \n",
      "61           8.4  \n",
      "62           8.4  \n",
      "63           8.4  \n",
      "64           8.4  \n",
      "65           8.4  \n",
      "66           8.3  \n",
      "67           8.3  \n",
      "68           8.3  \n",
      "69           8.3  \n",
      "70           8.3  \n",
      "71           8.3  \n",
      "72           8.3  \n",
      "73           8.3  \n",
      "74           8.3  \n",
      "75           8.3  \n",
      "76           8.3  \n",
      "77           8.3  \n",
      "78           8.3  \n",
      "79           8.3  \n",
      "80           8.3  \n",
      "81           8.3  \n",
      "82           8.3  \n",
      "83           8.3  \n",
      "84           8.3  \n",
      "85           8.3  \n",
      "86           8.3  \n",
      "87           8.3  \n",
      "88           8.3  \n",
      "89           8.3  \n",
      "90           8.3  \n",
      "91           8.3  \n",
      "92           8.3  \n",
      "93           8.3  \n",
      "94           8.3  \n",
      "95           8.3  \n",
      "96           8.3  \n",
      "97           8.3  \n",
      "98           8.3  \n",
      "99           8.3  \n"
     ]
    }
   ],
   "source": [
    "imdb(\"https://www.imdb.com/chart/top/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Q3. Write a python program to display IMDB’s Top rated 100 Indian movies’ data (i.e. Name, IMDB rating, Year of release) and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imdb_indian(url):\n",
    "    p3=requests.get(url)\n",
    "    #p3.content\n",
    "    \n",
    "    print(p3.status_code)\n",
    "    \n",
    "    s3=BeautifulSoup(p3.content, 'html.parser')\n",
    "    #print(s3.prettify())\n",
    "    \n",
    "    ind_title1=s3.find_all(\"td\", class_='titleColumn')\n",
    "    ind_movie=[]\n",
    "    for i in ind_title1:\n",
    "        for j in i.find_all(\"a\"):\n",
    "            ind_movie.append(j.text)\n",
    "            \n",
    "    ind_year_of_release=s3.find_all(\"span\", class_=\"secondaryInfo\")\n",
    "    ind_year=[]\n",
    "    for i in ind_year_of_release:\n",
    "        ind_year.append(i.text)\n",
    "        \n",
    "    ind_rating=s3.find_all(\"td\", class_='ratingColumn imdbRating')\n",
    "    ind_ratings=[]\n",
    "    for i in ind_rating:\n",
    "        for j in i.find_all(\"strong\"):\n",
    "            ind_ratings.append(j.text)\n",
    "            \n",
    "    IMDB_MOVIES_IND=pd.DataFrame()\n",
    "    IMDB_MOVIES_IND[\"Movie Title\"]=ind_movie[0:100]\n",
    "    IMDB_MOVIES_IND[\"Release Year\"]=ind_year[0:100]\n",
    "    IMDB_MOVIES_IND[\"Movie Rating\"]=ind_ratings[0:100]\n",
    "    \n",
    "    print(IMDB_MOVIES_IND)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "                          Movie Title Release Year Movie Rating\n",
      "0                     Pather Panchali       (1955)          8.5\n",
      "1                             Nayakan       (1987)          8.5\n",
      "2                   Pariyerum Perumal       (2018)          8.5\n",
      "3                          Anbe Sivam       (2003)          8.5\n",
      "4                             Golmaal       (1979)          8.5\n",
      "5                         Apur Sansar       (1959)          8.5\n",
      "6                   C/o Kancharapalem       (2018)          8.5\n",
      "7                    Manichitrathazhu       (1993)          8.4\n",
      "8                            Kireedam       (1989)          8.4\n",
      "9                           Natsamrat       (2016)          8.4\n",
      "10                         Drishyam 2       (2021)          8.4\n",
      "11                                 96       (2018)          8.4\n",
      "12                       Black Friday       (2004)          8.4\n",
      "13                       Thevar Magan       (1992)          8.4\n",
      "14                  Kumbalangi Nights       (2019)          8.4\n",
      "15                           3 Idiots       (2009)          8.3\n",
      "16                         Visaaranai       (2015)          8.3\n",
      "17                   Taare Zameen Par       (2007)          8.3\n",
      "18                             Jersey       (2019)          8.3\n",
      "19                           Ratsasan       (2018)          8.3\n",
      "20                         Thalapathi       (1991)          8.3\n",
      "21                             Dangal       (2016)          8.3\n",
      "22                    Soorarai Pottru       (2020)          8.3\n",
      "23                             Asuran       (2019)          8.3\n",
      "24                             Kaithi       (2019)          8.3\n",
      "25                          Aparajito       (1956)          8.3\n",
      "26                          Devasuram       (1993)          8.3\n",
      "27                 Jaane Bhi Do Yaaro       (1983)          8.3\n",
      "28                             Pyaasa       (1957)          8.3\n",
      "29                            Peranbu       (2018)          8.3\n",
      "30                              Guide       (1965)          8.3\n",
      "31                       Vada Chennai       (2018)          8.3\n",
      "32                       Thani Oruvan       (2015)          8.2\n",
      "33              Kannathil Muthamittal       (2002)          8.2\n",
      "34                      Chupke Chupke       (1975)          8.2\n",
      "35                             Iruvar       (1997)          8.2\n",
      "36                           Spadikam       (1995)          8.2\n",
      "37        Agent Sai Srinivasa Athreya       (2019)          8.2\n",
      "38                           Drishyam       (2013)          8.2\n",
      "39                       Vikram Vedha       (2017)          8.2\n",
      "40                       Super Deluxe       (2019)          8.2\n",
      "41                              Aruvi       (2016)          8.2\n",
      "42                            Tumbbad       (2018)          8.2\n",
      "43                           Mahanati       (2018)          8.2\n",
      "44                  Khosla Ka Ghosla!       (2006)          8.2\n",
      "45                              Anand       (1971)          8.2\n",
      "46                       Pudhu Pettai       (2006)          8.2\n",
      "47                             Premam       (2015)          8.2\n",
      "48                     Kaakkaa Muttai       (2014)          8.2\n",
      "49                            Anniyan       (2005)          8.2\n",
      "50                          Andhadhun       (2018)          8.2\n",
      "51                     Bangalore Days       (2014)          8.2\n",
      "52                          Mudhalvan       (1999)          8.2\n",
      "53             Dhuruvangal Pathinaaru       (2016)          8.2\n",
      "54                          Papanasam       (2015)          8.2\n",
      "55                              Satya       (1998)          8.2\n",
      "56                             Shahid       (2012)          8.2\n",
      "57                      Soodhu Kavvum       (2013)          8.2\n",
      "58                        Jigarthanda       (2014)          8.1\n",
      "59                         Pithamagan       (2003)          8.1\n",
      "60                 Gangs of Wasseypur       (2012)          8.1\n",
      "61                   Paan Singh Tomar       (2012)          8.1\n",
      "62                             Sairat       (2016)          8.1\n",
      "63                 Bhaag Milkha Bhaag       (2013)          8.1\n",
      "64                             Talvar       (2015)          8.1\n",
      "65                         Hera Pheri       (2000)          8.1\n",
      "66             Swades: We, the People       (2004)          8.1\n",
      "67                             Sholay       (1975)          8.1\n",
      "68                              Black       (2005)          8.1\n",
      "69                     Chak De! India       (2007)          8.1\n",
      "70                        Ustad Hotel       (2012)          8.1\n",
      "71                 Nil Battey Sannata       (2015)          8.1\n",
      "72             Jo Jeeta Wohi Sikandar       (1992)          8.1\n",
      "73                           Drishyam       (2015)          8.1\n",
      "74                      Mughal-E-Azam       (1960)          8.1\n",
      "75                          Charulata       (1964)          8.1\n",
      "76           Zindagi Na Milegi Dobara       (2011)          8.1\n",
      "77            Maheshinte Prathikaaram       (2016)          8.1\n",
      "78                         Article 15       (2019)          8.1\n",
      "79                              Udaan       (2010)          8.1\n",
      "80                        A Wednesday       (2008)          8.1\n",
      "81           Theeran adhigaaram ondru       (2017)          8.1\n",
      "82                              Queen       (2013)          8.1\n",
      "83                             Masaan       (2015)          8.1\n",
      "84                          Sarfarosh       (1999)          8.1\n",
      "85                Munna Bhai M.B.B.S.       (2003)          8.1\n",
      "86                      Alai Payuthey       (2000)          8.1\n",
      "87                     Dil Chahta Hai       (2001)          8.1\n",
      "88                               Roja       (1992)          8.1\n",
      "89                    OMG: Oh My God!       (2012)          8.1\n",
      "90                             Baasha       (1995)          8.1\n",
      "91                    Rang De Basanti       (2006)          8.1\n",
      "92  Lagaan: Once Upon a Time in India       (2001)          8.1\n",
      "93                            Kahaani       (2012)          8.1\n",
      "94                    Andaz Apna Apna       (1994)          8.1\n",
      "95                         Chhichhore       (2019)          8.1\n",
      "96           Uri: The Surgical Strike       (2018)          8.1\n",
      "97                          Virumandi       (2004)          8.1\n",
      "98                                 PK       (2014)          8.1\n",
      "99                              Lucia       (2013)          8.1\n"
     ]
    }
   ],
   "source": [
    "imdb_indian(\"https://www.imdb.com/india/top-rated-indian-movies/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Q4. Write a python program to scrap book name, author name, genre and book review of any 5 books from ‘www.bookpage.com’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bookreview(url):\n",
    "    p4=requests.get(url)\n",
    "    #p4.content\n",
    "    \n",
    "    print(p4.status_code)\n",
    "    \n",
    "    s4=BeautifulSoup(p4.content, \"html.parser\")\n",
    "    #print(s4.prettify())\n",
    "    \n",
    "    book=s4.find_all(\"h4\", class_=\"italic\")\n",
    "    book_name=[]\n",
    "    for i in book:\n",
    "        for j in i.find_all(\"a\"):\n",
    "            book_name.append(j.text.strip(\"\\n\"))\n",
    "            \n",
    "    author=s4.find_all(\"p\", class_='sans bold')\n",
    "    book_author=[]\n",
    "    for i in author:\n",
    "        book_author.append(i.text.strip(\"\\n\"))\n",
    "        \n",
    "    review=s4.find_all(\"p\", class_='excerpt')\n",
    "    book_review=[]\n",
    "    for i in review:\n",
    "        book_review.append(i.text.strip(\"\\n\"))\n",
    "        \n",
    "    BOOK_REVIEWS=pd.DataFrame()\n",
    "    BOOK_REVIEWS[\"Book Name\"]=book_name[0:5]\n",
    "    BOOK_REVIEWS[\"Author\"]=book_author[0:5]\n",
    "    BOOK_REVIEWS[\"Reviews\"]=book_review[0:5]\n",
    "    \n",
    "    print(BOOK_REVIEWS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "                   Book Name                Author  \\\n",
      "0             ★ The Ugly Cry    Danielle Henderson   \n",
      "1    ★ Indestructible Object            Mary McCoy   \n",
      "2   ★ How the Word Is Passed           Clint Smith   \n",
      "3       ★ Seven Days in June          Tia Williams   \n",
      "4     ★ The Other Black Girl  Zakiya Dalila Harris   \n",
      "\n",
      "                                             Reviews  \n",
      "0  Danielle Henderson brings her family to life u...  \n",
      "1  With her parents’ looming divorce echoing her ...  \n",
      "2  Clint Smith's gifts as both a poet and a schol...  \n",
      "3  Readers will feel as attached to Tia Williams’...  \n",
      "4  Brilliantly positioned at the intersection of ...  \n"
     ]
    }
   ],
   "source": [
    "bookreview(\"https://bookpage.com/reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Q5. Write a python program to scrape cricket rankings from ‘www.icc-cricket.com’. You have to scrape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "         i. Top 10 ODI teams in men’s cricket along with the records for matches, points and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ODI_MEN(url):\n",
    "    p5 = requests.get(url)\n",
    "    #p5.content\n",
    "    print(p5.status_code)\n",
    "    \n",
    "    s5 = BeautifulSoup(p5.content, \"html.parser\")\n",
    "    #print(s5.prettify())\n",
    "    \n",
    "    team1 = s5.find_all('span', class_='u-hide-phablet')\n",
    "    Team_Name = []\n",
    "    for i in team1:\n",
    "        Team_Name.append(i.text)\n",
    "        \n",
    "    match1 = s5.find_all('td', class_='rankings-block__banner--matches')\n",
    "    Matches = []\n",
    "    for i in match1:\n",
    "        Matches.append(i.text)\n",
    "        \n",
    "    point1 = s5.find_all('td', class_='rankings-block__banner--points')\n",
    "    Point = []\n",
    "    for i in point1:\n",
    "        Point.append(i.text) \n",
    "    \n",
    "    rating1 = s5.find_all('td', class_='rankings-block__banner--rating u-text-right')\n",
    "    Rating = []\n",
    "    for i in rating1:\n",
    "        Rating.append(i.text.strip('\\n'))\n",
    "    Ratings = [] \n",
    "    Ratings.append(Rating[0].strip())\n",
    "    \n",
    "    match1 = s5.find_all('td', class_='table-body__cell u-center-text')\n",
    "    k = []\n",
    "    for i in range(0,len(match1),2):\n",
    "        k.append(match1[i])\n",
    "    for i in k:\n",
    "        Matches.append(i.get_text())\n",
    "        \n",
    "    k = []\n",
    "    for i in range(1,len(match1),2):\n",
    "        k.append(match1[i])\n",
    "    for i in k:\n",
    "        Point.append(i.get_text())\n",
    "        \n",
    "    rating1 = s5.find_all('td', class_='table-body__cell u-text-right rating')\n",
    "    for i in rating1:\n",
    "        Ratings.append(i.get_text().strip('\\n'))\n",
    "        \n",
    "    ODI_MEN = pd.DataFrame()\n",
    "    ODI_MEN['Team_Name'] = Team_Name[0:10]\n",
    "    ODI_MEN['Matches'] = Matches[0:10]\n",
    "    ODI_MEN['Ratings'] = Ratings[0:10]\n",
    "    ODI_MEN['Point'] = Point[0:10]\n",
    "    \n",
    "    print(ODI_MEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "      Team_Name Matches Ratings  Point\n",
      "0   New Zealand      17     121  2,054\n",
      "1     Australia      25     118  2,945\n",
      "2         India      29     115  3,344\n",
      "3       England      27     115  3,100\n",
      "4  South Africa      20     107  2,137\n",
      "5      Pakistan      24      97  2,323\n",
      "6    Bangladesh      27      90  2,438\n",
      "7   West Indies      27      82  2,222\n",
      "8     Sri Lanka      24      78  1,876\n",
      "9   Afghanistan      17      62  1,054\n"
     ]
    }
   ],
   "source": [
    "ODI_MEN(\"https://www.icc-cricket.com/rankings/mens/team-rankings/odi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "               ii. Top 10 ODI Batsmen in men along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ODI_Batsmen(url):\n",
    "    p5=requests.get(url)\n",
    "    #p5.content\n",
    "    \n",
    "    print(p5.status_code)\n",
    "    \n",
    "    s5=BeautifulSoup(p5.content, \"html.parser\")\n",
    "    #print(s5.prettify())\n",
    "    \n",
    "    player=s5.find_all('div', class_='rankings-block__banner--name-large')\n",
    "    player_name=[]\n",
    "    for i in player:\n",
    "        player_name.append(i.text)\n",
    "        \n",
    "    player2=s5.find_all('td', class_='table-body__cell rankings-table__name name')\n",
    "    for i in player2:\n",
    "        for j in i.find_all(\"a\"):\n",
    "            player_name.append(j.text)\n",
    "        \n",
    "    team1=s5.find_all(\"div\", class_=\"rankings-block__banner--nationality\")\n",
    "    team_name=[]\n",
    "    for i in team1:\n",
    "        team_name.append(i.text.replace(\"\\n\",\"\"))\n",
    "        \n",
    "    team2=s5.find_all(\"span\", class_='table-body__logo-text')\n",
    "    for i in team2:\n",
    "        team_name.append(i.text)\n",
    "        \n",
    "    rating1=s5.find_all(\"div\", class_=\"rankings-block__banner--rating\")\n",
    "    player_rating=[]\n",
    "    for i in rating1:\n",
    "        player_rating.append(i.text)\n",
    "        \n",
    "    rating2=s5.find_all(\"td\", class_=\"table-body__cell rating\")\n",
    "    for i in rating2:\n",
    "        player_rating.append(i.text)\n",
    "        \n",
    "    ODI_BATSMEN_RANKINGS=pd.DataFrame()\n",
    "    ODI_BATSMEN_RANKINGS[\"Player Name\"]=player_name[0:10]\n",
    "    ODI_BATSMEN_RANKINGS[\"Team\"]=team_name[0:10]\n",
    "    ODI_BATSMEN_RANKINGS[\"Rating\"]=player_rating[0:10]\n",
    "    \n",
    "    print(ODI_BATSMEN_RANKINGS)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "           Player Name Team Rating\n",
      "0           Babar Azam  PAK    865\n",
      "1          Virat Kohli  IND    857\n",
      "2         Rohit Sharma  IND    825\n",
      "3          Ross Taylor   NZ    801\n",
      "4          Aaron Finch  AUS    791\n",
      "5       Jonny Bairstow  ENG    785\n",
      "6         Fakhar Zaman  PAK    778\n",
      "7  Francois du Plessis   SA    778\n",
      "8         David Warner  AUS    773\n",
      "9            Shai Hope   WI    773\n"
     ]
    }
   ],
   "source": [
    "ODI_Batsmen(\"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/Batting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "                iii. Top 10 ODI bowlers along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ODI_Bowler(url):\n",
    "    p5=requests.get(url)\n",
    "    #p5.content\n",
    "    \n",
    "    print(p5.status_code)\n",
    "    \n",
    "    s5=BeautifulSoup(p5.content,\"html.parser\")\n",
    "    #print(s5.prettify())\n",
    "    \n",
    "    player1=s5.find_all(\"div\",class_=\"rankings-block__banner--name-large\")\n",
    "    player_name=[]\n",
    "    for i in player1:\n",
    "        player_name.append(i.text)\n",
    "        \n",
    "    player2=s5.find_all(\"td\",class_=\"table-body__cell rankings-table__name name\")\n",
    "    for i in player2:\n",
    "        player_name.append(i.text.replace(\"\\n\",\"\"))\n",
    "        \n",
    "    team1=s5.find_all(\"div\",class_=\"rankings-block__banner--nationality\")\n",
    "    team_name=[]\n",
    "    for i in team1:\n",
    "        team_name.append(i.text.replace(\"\\n\",\"\"))\n",
    "        \n",
    "    team2=s5.find_all(\"span\",class_=\"table-body__logo-text\")\n",
    "    for i in team2:\n",
    "        team_name.append(i.text)\n",
    "        \n",
    "    rating1=s5.find_all(\"div\",class_=\"rankings-block__banner--rating\")\n",
    "    player_rating=[]\n",
    "    for i in rating1:\n",
    "        player_rating.append(i.text)\n",
    "        \n",
    "    rating2=s5.find_all(\"td\",class_=\"table-body__cell rating\")\n",
    "    for i in rating2:\n",
    "        player_rating.append(i.text)\n",
    "        \n",
    "    \n",
    "    ODI_BOWLER_RANKINGS=pd.DataFrame()\n",
    "    ODI_BOWLER_RANKINGS[\"Player Name\"]=player_name[0:10]\n",
    "    ODI_BOWLER_RANKINGS[\"Team\"]=team_name[0:10]\n",
    "    ODI_BOWLER_RANKINGS[\"Ratings\"]=player_rating[0:10]\n",
    "    \n",
    "    print(ODI_BOWLER_RANKINGS)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "         Player Name Team Ratings\n",
      "0        Trent Boult   NZ     737\n",
      "1       Mehedi Hasan  BAN     713\n",
      "2   Mujeeb Ur Rahman  AFG     708\n",
      "3         Matt Henry   NZ     691\n",
      "4     Jasprit Bumrah  IND     690\n",
      "5      Kagiso Rabada   SA     666\n",
      "6       Chris Woakes  ENG     665\n",
      "7     Josh Hazlewood  AUS     660\n",
      "8        Pat Cummins  AUS     646\n",
      "9  Mustafizur Rahman  BAN     645\n"
     ]
    }
   ],
   "source": [
    "ODI_Bowler(\"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/Bowling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Q6. Write a python program to scrape cricket rankings from ‘www.icc-cricket.com’. You have to scrape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "         i. Top 10 ODI teams in women’s cricket along with the records for matches, points and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ODI_WOMEN(url):\n",
    "    p6 = requests.get(url)\n",
    "    #p6.content\n",
    "    print(p6.status_code)\n",
    "    \n",
    "    s6 = BeautifulSoup(p6.content, \"html.parser\")\n",
    "    #print(s6.prettify())\n",
    "    \n",
    "    team1 = s6.find_all('span', class_='u-hide-phablet')\n",
    "    Team_Name = []\n",
    "    for i in team1:\n",
    "        Team_Name.append(i.text)\n",
    "        \n",
    "    match1 = s6.find_all('td', class_='rankings-block__banner--matches')\n",
    "    Matches = []\n",
    "    for i in match1:\n",
    "        Matches.append(i.text)\n",
    "        \n",
    "    point1 = s6.find_all('td', class_='rankings-block__banner--points')\n",
    "    Point = []\n",
    "    for i in point1:\n",
    "        Point.append(i.text) \n",
    "    \n",
    "    rating1 = s6.find_all('td', class_='rankings-block__banner--rating u-text-right')\n",
    "    Rating = []\n",
    "    for i in rating1:\n",
    "        Rating.append(i.text.strip('\\n'))\n",
    "    Ratings = [] \n",
    "    Ratings.append(Rating[0].strip())\n",
    "    \n",
    "    match1 = s6.find_all('td', class_='table-body__cell u-center-text')\n",
    "    k = []\n",
    "    for i in range(0,len(match1),2):\n",
    "        k.append(match1[i])\n",
    "    for i in k:\n",
    "        Matches.append(i.get_text())\n",
    "        \n",
    "    k = []\n",
    "    for i in range(1,len(match1),2):\n",
    "        k.append(match1[i])\n",
    "    for i in k:\n",
    "        Point.append(i.get_text())\n",
    "        \n",
    "    rating1 = s6.find_all('td', class_='table-body__cell u-text-right rating')\n",
    "    for i in rating1:\n",
    "        Ratings.append(i.get_text().strip('\\n'))\n",
    "            \n",
    "    ODI_Women = pd.DataFrame()\n",
    "    ODI_Women['Team_Name'] = Team_Name[0:10]\n",
    "    ODI_Women['Matches'] = Matches[0:10]\n",
    "    ODI_Women['Ratings'] = Ratings[0:10]\n",
    "    ODI_Women['Point'] = Point[0:10]\n",
    "    \n",
    "    print(ODI_Women)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "      Team_Name Matches Ratings  Point\n",
      "0     Australia      18     164  2,955\n",
      "1  South Africa      24     118  2,828\n",
      "2       England      17     117  1,993\n",
      "3         India      20     111  2,226\n",
      "4   New Zealand      21      93  1,947\n",
      "5   West Indies      12      85  1,025\n",
      "6      Pakistan      15      73  1,101\n",
      "7    Bangladesh       5      61    306\n",
      "8     Sri Lanka      11      47    519\n",
      "9       Ireland       2      13     25\n"
     ]
    }
   ],
   "source": [
    "ODI_WOMEN(\"https://www.icc-cricket.com/rankings/womens/team-rankings/odi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "                ii. Top 10 women’s ODI players along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ODI_Woman(url):\n",
    "    p6 = requests.get(url)\n",
    "    #p6.content\n",
    "    print(p6.status_code)\n",
    "    \n",
    "    s6 = BeautifulSoup(p6.content, \"html.parser\")\n",
    "    #print(s6.prettify())\n",
    "    \n",
    "    player1 = s6.find_all('div', class_='rankings-block__banner--name-large')\n",
    "    Player = []\n",
    "    for i in player1:\n",
    "        Player.append(i.text)\n",
    "    \n",
    "    player2 = s6.find_all('td', class_='table-body__cell rankings-table__name name')\n",
    "    for i in player2:\n",
    "        for j in i.find_all(\"a\"):\n",
    "            Player.append(j.text)\n",
    "            \n",
    "    team1 = s6.find(\"div\", class_=\"rankings-block__banner--nationality\")\n",
    "    Team = []\n",
    "    Team.append(team1.text.strip())\n",
    "    \n",
    "    team2 = s6.find_all(\"span\", class_='table-body__logo-text')\n",
    "    for i in team2:\n",
    "        Team.append(i.text)\n",
    "        \n",
    "    rating1 = s6.find_all('td', class_='table-body__cell rating')\n",
    "    Rating = []\n",
    "    for i in rating1:\n",
    "        Rating.append(i.text)\n",
    "        \n",
    "    ODI_Woman = pd.DataFrame()\n",
    "    ODI_Woman['Team'] = Team[0:10]\n",
    "    ODI_Woman['Player'] = Player[0:10]\n",
    "    ODI_Woman['Rating'] = Rating[0:10]\n",
    "    print(ODI_Woman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "  Team             Player Rating\n",
      "0  ENG     Tammy Beaumont    758\n",
      "1   SA        Lizelle Lee    756\n",
      "2  AUS       Alyssa Healy    746\n",
      "3   WI    Stafanie Taylor    723\n",
      "4  AUS        Meg Lanning    715\n",
      "5   NZ  Amy Satterthwaite    710\n",
      "6  IND    Smriti Mandhana    709\n",
      "7  IND        Mithali Raj    685\n",
      "8  ENG     Natalie Sciver    683\n",
      "9   SA    Laura Wolvaardt    679\n"
     ]
    }
   ],
   "source": [
    "ODI_Woman(\"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "            iii. Top 10 women’s ODI all-rounder along with the records of their team and rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ODI_Allrounder_Woman(url):\n",
    "    p6 = requests.get(url)\n",
    "    #p6.content\n",
    "    print(p6.status_code)\n",
    "    \n",
    "    s6 = BeautifulSoup(p6.content, \"html.parser\")\n",
    "    #print(s6.prettify())\n",
    "    \n",
    "    player1 = s6.find_all('div', class_='rankings-block__banner--name-large')\n",
    "    Player = []\n",
    "    for i in player1:\n",
    "        Player.append(i.text)\n",
    "    \n",
    "    player2 = s6.find_all('td', class_='table-body__cell rankings-table__name name')\n",
    "    for i in player2:\n",
    "        for j in i.find_all(\"a\"):\n",
    "            Player.append(j.text)\n",
    "            \n",
    "    team1 = s6.find(\"div\", class_=\"rankings-block__banner--nationality\")\n",
    "    Team = []\n",
    "    Team.append(team1.text.strip())\n",
    "    \n",
    "    team2 = s6.find_all(\"span\", class_='table-body__logo-text')\n",
    "    for i in team2:\n",
    "        Team.append(i.text)\n",
    "        \n",
    "    rating1 = s6.find_all('td', class_='table-body__cell rating')\n",
    "    Rating = []\n",
    "    for i in rating1:\n",
    "        Rating.append(i.text)\n",
    "        \n",
    "    ODI_Allrounder_Woman = pd.DataFrame()\n",
    "    ODI_Allrounder_Woman['Team'] = Team[0:10]\n",
    "    ODI_Allrounder_Woman['Player'] = Player[0:10]\n",
    "    ODI_Allrounder_Woman['Rating'] = Rating[0:10]\n",
    "    \n",
    "    print(ODI_Allrounder_Woman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "  Team            Player Rating\n",
      "0   SA    Marizanne Kapp    418\n",
      "1  AUS      Ellyse Perry    410\n",
      "2   WI   Stafanie Taylor    349\n",
      "3  ENG    Natalie Sciver    343\n",
      "4  IND     Deepti Sharma    307\n",
      "5  AUS     Jess Jonassen    252\n",
      "6  AUS  Ashleigh Gardner    243\n",
      "7   SA  Dane van Niekerk    242\n",
      "8   NZ     Sophie Devine    236\n",
      "9   NZ       Amelia Kerr    236\n"
     ]
    }
   ],
   "source": [
    "ODI_Allrounder_Woman(\"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Q7. Write a python program to scrape details of all the mobile phones under Rs. 20,000 listed on Amazon.in. The scraped data should include Product Name, Price, Image URL and Average Rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p7=requests.get(\"https://www.amazon.in/Smartphones-%E2%82%B910-000-%E2%82%B920-Basic-Mobiles/s?rh=n%3A1805560031%2Cp_36%3A1318506031\")\n",
    "p7"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# As we can see we are not getting Response 200 and inplace getting Response 503, so we cannot extract data using Web Scraping as this webpage does not allow web scraping to extract data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Q8. Write a python program to extract information about the local weather from the National Weather Service website of USA, https://www.weather.gov/ for the city, San Francisco. You need to extract data about 7 day extended forecast display for the city. The data should include period, short description, temperature and description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Q9. Write a python program to scrape fresher job listings from ‘https://internshala.com/’. It should include job title, company name, CTC, and apply date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Job_Search(url):\n",
    "    p9 = requests.get(url)\n",
    "    #p9.content\n",
    "    print(p9.status_code)\n",
    "    \n",
    "    s9 = BeautifulSoup(p9.content, \"html.parser\")\n",
    "    #print(s9.prettify())\n",
    "    \n",
    "    job_title = []\n",
    "    company_name = []\n",
    "    annual_ctc = []\n",
    "    apply_date = []\n",
    "    \n",
    "    temp = []\n",
    "    \n",
    "    get_titles = s9.find_all('div',class_ = \"heading_4_5 profile\")   \n",
    "    get_companies = s9.find_all('a', class_ = 'link_display_like_text')\n",
    "    get_ctcadate = s9.find_all('div',class_ = \"item_body\", id = False)\n",
    "    \n",
    "    for cdate in get_ctcadate:\n",
    "        temp.append(cdate.text.strip())\n",
    "        \n",
    "    for t, c in zip(get_titles, get_companies):\n",
    "        job_title.append(t.text.strip())\n",
    "        company_name.append(c.text.strip())\n",
    "    \n",
    "    for i in temp:\n",
    "        annual_ctc.append(i) if 'LPA' in i else apply_date.append(i)\n",
    "            \n",
    "    Job_Search = pd.DataFrame({'Title': job_title,\n",
    "                     'Company': company_name,\n",
    "                     'CTC': annual_ctc,\n",
    "                     'Apply Date': apply_date\n",
    "                     })\n",
    "    \n",
    "    print(Job_Search.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "                               Title                        Company  \\\n",
      "0            PHP & LARAVEL DEVELOPER                     Nyx Wolves   \n",
      "1  Backend Developer (Ruby On Rails)  Wollfish Labs Private Limited   \n",
      "2        Customer Service Specialist                       Wono Inc   \n",
      "3                   Graphic Designer                       Wono Inc   \n",
      "4       Digital Marketing Specialist                       Wono Inc   \n",
      "\n",
      "             CTC Apply Date  \n",
      "0   3 - 3.05 LPA  4 Jul' 21  \n",
      "1      6 - 8 LPA  4 Jul' 21  \n",
      "2  5.2 - 6.4 LPA  3 Jul' 21  \n",
      "3    5 - 6.5 LPA  3 Jul' 21  \n",
      "4    5 - 6.5 LPA  3 Jul' 21  \n"
     ]
    }
   ],
   "source": [
    "Job_Search(\"https://internshala.com/fresher-jobs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
